{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "39fa55a3-bee5-4e6f-ad45-25af9d01cd82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Reading': ['47'], 'units': ['mg/dL'], 'date': ['10/26/20'], 'time': ['9:25 am'], 'deviceName': ['ACCUCHEK Guide']}\n"
     ]
    }
   ],
   "source": [
    "from google.cloud import vision\n",
    "from google.oauth2 import service_account\n",
    "from google.cloud import vision_v1\n",
    "from google.protobuf import json_format\n",
    "import os\n",
    "import re\n",
    "\n",
    "key_path = 'KEY_FILE.json'\n",
    "credentials = service_account.Credentials.from_service_account_file(key_path)\n",
    "client = vision.ImageAnnotatorClient(credentials=credentials)\n",
    "\n",
    "def get_values_from_image(image_file_name):\n",
    "\n",
    "    # Read the image file\n",
    "    with open(image_file_name, 'rb') as image_file:\n",
    "        content = image_file.read()\n",
    "\n",
    "    # Create an image object\n",
    "    image = vision_v1.Image(content=content)\n",
    "    image_context = vision_v1.ImageContext(language_hints=[\"en\"])\n",
    "\n",
    "    # Perform text detection on the image\n",
    "    response = client.text_detection(image=image, image_context=image_context)\n",
    "    extracted_text = response.text_annotations\n",
    "\n",
    "    cleaned_text = \"\"\n",
    "    for text in extracted_text:\n",
    "        text_description = text.description\n",
    "        if isinstance(text_description, str):\n",
    "            cleaned_text += re.sub(r'[^\\w\\s./:]', '', text_description) + \" \"\n",
    "\n",
    "    one_line_text = \" \".join(cleaned_text.split())\n",
    "\n",
    "    # Initialize the spaCy NER model (assuming 'nlp_ner' is a valid NER model)\n",
    "    nlp_ner = spacy.load(\"model-best\")\n",
    "\n",
    "    # Process the one-line text with spaCy NER\n",
    "    doc = nlp_ner(one_line_text)\n",
    "\n",
    "    # Extract entities\n",
    "    readings = [ent.text for ent in doc.ents if ent.label_ == \"BG READING\"]\n",
    "    units = [ent.text for ent in doc.ents if ent.label_ == \"UNITS\"]\n",
    "    date = [ent.text for ent in doc.ents if ent.label_ == \"DATE\"]\n",
    "    time = [ent.text for ent in doc.ents if ent.label_ == \"TIME\"]\n",
    "    deviceName = [ent.text for ent in doc.ents if ent.label_ == \"DEVICE NAME\"]\n",
    "\n",
    "    # Create a dictionary to store the results\n",
    "    result = {\n",
    "        \"Reading\": readings,\n",
    "        \"units\": units,\n",
    "        \"date\": date,\n",
    "        \"time\": time,\n",
    "        \"deviceName\": deviceName\n",
    "    }\n",
    "\n",
    "    return result\n",
    "\n",
    "image_file_name = 'bgReading_4.jpeg'\n",
    "result = get_values_from_image(image_file_name)\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
